{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2LcgrwNPwRT",
        "outputId": "37e55681-be00-4e83-ac73-f272854588cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/868.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m860.2/868.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CBIS-DDSM (Kaggle) → torchvision (EfficientNetV2-S)\n",
        "# ROI tabanlı benign/malign sınıflandırma (Colab, tek parça)\n",
        "# Çıktılar: /content/drive/MyDrive/breast_cancer\n",
        "# Albumentations / OpenCV / timm YOK → torchvision.transforms + PIL\n",
        "# ============================================================\n",
        "\n",
        "# ---- 0) Minimal kurulum ----\n",
        "!pip -q install --upgrade pip setuptools wheel kaggle scikit-learn==1.6.1 torchmetrics==1.4.0.post0\n",
        "\n",
        "import os, json, time, random, math, shutil, zipfile, tarfile, re\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import StratifiedGroupKFold, train_test_split\n",
        "from sklearn.metrics import (roc_auc_score, accuracy_score, f1_score,\n",
        "                             confusion_matrix, classification_report,\n",
        "                             ConfusionMatrixDisplay, roc_curve,\n",
        "                             precision_recall_curve, average_precision_score)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 2) Google Drive mount (sağlam) ----\n",
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "OUTPUT_DIR = Path('/content/drive/MyDrive/breast_cancer')\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(\"Çıktılar:\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9whetmmUQVHi",
        "outputId": "5824dba0-435b-4b8f-9088-2331337a9d7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Çıktılar: /content/drive/MyDrive/breast_cancer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 3) Kaggle kimliği ve veri indirme ----\n",
        "from google.colab import files\n",
        "KAGGLE_DIR = Path('/root/.kaggle'); KAGGLE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "if not (KAGGLE_DIR/'kaggle.json').exists():\n",
        "    print(\"Lütfen bilgisayarındaki kaggle.json dosyasını seç.\")\n",
        "    up = files.upload()\n",
        "    if 'kaggle.json' not in up: raise RuntimeError(\"kaggle.json gerekli.\")\n",
        "    with open(KAGGLE_DIR/'kaggle.json', 'wb') as f: f.write(up['kaggle.json'])\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "DATA_ROOT = Path('/content/cbis_ddsm'); DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "!kaggle datasets download -d awsaf49/cbis-ddsm-breast-cancer-image-dataset -p {DATA_ROOT} -q\n",
        "for z in DATA_ROOT.glob('*.zip'):\n",
        "    shutil.unpack_archive(str(z), extract_dir=str(DATA_ROOT))\n",
        "    z.unlink()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "FvJUyf1aQZQl",
        "outputId": "03759532-da4c-4e32-b7de-2f1ae2971595"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lütfen bilgisayarındaki kaggle.json dosyasını seç.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-505f7efc-00e5-4ab0-a9b3-9d5776d32488\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-505f7efc-00e5-4ab0-a9b3-9d5776d32488\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/awsaf49/cbis-ddsm-breast-cancer-image-dataset\n",
            "License(s): CC-BY-SA-3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 4) İç içe arşivleri aç & envanter ----\n",
        "def unpack_all_archives(root: Path, max_pass=2):\n",
        "    for _ in range(max_pass):\n",
        "        changed = False\n",
        "        for p in list(root.rglob('*')):\n",
        "            if not p.is_file(): continue\n",
        "            low = p.name.lower()\n",
        "            try:\n",
        "                if low.endswith('.zip'):\n",
        "                    with zipfile.ZipFile(p, 'r') as z: z.extractall(p.parent)\n",
        "                    p.unlink(); changed = True\n",
        "                elif low.endswith(('.tar', '.tar.gz', '.tgz')):\n",
        "                    with tarfile.open(p, 'r:*') as t: t.extractall(p.parent)\n",
        "                    p.unlink(); changed = True\n",
        "            except Exception as e:\n",
        "                print(\"Arşiv açılamadı:\", p, \"->\", e)\n",
        "        if not changed: break\n",
        "\n",
        "unpack_all_archives(DATA_ROOT)\n",
        "\n",
        "all_files = [p for p in DATA_ROOT.rglob('*') if p.is_file()]\n",
        "ext_count = Counter([p.suffix.lower() for p in all_files])\n",
        "print(f\"[INFO] Toplam dosya: {len(all_files)}\")\n",
        "print(\"[INFO] Uzantı sayıları:\", dict(ext_count))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH_oZl1lQbXl",
        "outputId": "bba52939-ec56-4023-a568-681a8a2b5f26"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Toplam dosya: 10243\n",
            "[INFO] Uzantı sayıları: {'.csv': 6, '.jpg': 10237}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== 5. KISIM (GENEL ÇÖZÜM – DÜZELTİLMİŞ) =====================\n",
        "from pathlib import Path\n",
        "import pandas as pd, numpy as np, re\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import StratifiedGroupKFold, train_test_split\n",
        "\n",
        "DATA_ROOT = Path('/content/cbis_ddsm')\n",
        "assert DATA_ROOT.exists(), f\"{DATA_ROOT} yok; indirme/açma kısmını çalıştır.\"\n",
        "\n",
        "# 1) Klasördeki TÜM .jpg dosyaları\n",
        "jpgs = sorted([p for p in DATA_ROOT.rglob('*.jpg')])\n",
        "jpg_names = set(p.name for p in jpgs)\n",
        "print(f\"[INFO] JPG sayısı: {len(jpgs)}\")\n",
        "print(\"[INFO] Örnek JPG'ler:\", [p.name for p in jpgs[:10]])\n",
        "\n",
        "# 2) CSV’leri topla (mass/calc + meta/dicom_info dahil)\n",
        "wanted = {\n",
        "    'mass_case_description_train_set.csv',\n",
        "    'mass_case_description_test_set.csv',\n",
        "    'calc_case_description_train_set.csv',\n",
        "    'calc_case_description_test_set.csv',\n",
        "    'meta.csv',\n",
        "    'dicom_info.csv'\n",
        "}\n",
        "csvs = []\n",
        "for w in wanted:\n",
        "    csvs.extend(list(DATA_ROOT.rglob(w)))\n",
        "# yedek: kökteki tüm csv'ler\n",
        "if not csvs:\n",
        "    csvs = sorted(DATA_ROOT.rglob('*.csv'))\n",
        "print(\"[INFO] Kullanılacak CSV'ler:\", [c.name for c in csvs])\n",
        "\n",
        "# 3) Kolon seçim yardımcıları\n",
        "def pick_label_col(cols_lower_map):\n",
        "    # pathology > label > class\n",
        "    if 'pathology' in cols_lower_map: return cols_lower_map['pathology']\n",
        "    for k in ('label','class'):\n",
        "        if k in cols_lower_map: return cols_lower_map[k]\n",
        "    # fallback\n",
        "    for k in cols_lower_map:\n",
        "        if 'patholog' in k: return cols_lower_map[k]\n",
        "    return None\n",
        "\n",
        "def normalize_label(v):\n",
        "    if v is None: return None\n",
        "    s = str(v).strip().lower()\n",
        "    if 'benign' in s or s in ('b','0'): return 'benign'\n",
        "    if 'malig'  in s or s in ('m','1'): return 'malignant'\n",
        "    return None\n",
        "\n",
        "def score_filename_column(series):\n",
        "    \"\"\"Serideki değerlerin base name'i jpg_names içinde kaç tane eşleşiyor?\"\"\"\n",
        "    try:\n",
        "        vals = series.astype(str)\n",
        "    except Exception:\n",
        "        return 0\n",
        "    hit = 0\n",
        "    for v in vals:\n",
        "        if not v or v == 'nan':\n",
        "            continue\n",
        "        base = Path(str(v)).name  # '.../foo.jpg' -> 'foo.jpg'\n",
        "        if base in jpg_names:\n",
        "            hit += 1\n",
        "    return hit\n",
        "\n",
        "# 4) CSV’lerden direkt .jpg adı yakalamaya çalış\n",
        "pairs = []  # (jpg_path, label)\n",
        "\n",
        "for csv_path in csvs:\n",
        "    # Birkaç kodlama ayrıntısı için esnek okuma denemeleri\n",
        "    dfc = None\n",
        "    for kwargs in ({}, {\"sep\":\";\"}, {\"encoding\":\"latin1\"}, {\"sep\":\";\",\"encoding\":\"latin1\"}):\n",
        "        try:\n",
        "            dfc = pd.read_csv(csv_path, **kwargs)\n",
        "            break\n",
        "        except Exception:\n",
        "            continue\n",
        "    if dfc is None or dfc.empty:\n",
        "        print(f\"[WARN] CSV okunamadı/boş: {csv_path.name}\")\n",
        "        continue\n",
        "\n",
        "    cols_map = {c.lower(): c for c in dfc.columns}\n",
        "    ycol = pick_label_col(cols_map)\n",
        "\n",
        "    # Tüm kolonları gezip file name olma skorunu hesapla\n",
        "    col_hits = []\n",
        "    for c in dfc.columns:\n",
        "        h = score_filename_column(dfc[c])\n",
        "        if h > 0:\n",
        "            col_hits.append((h, c))\n",
        "    col_hits.sort(reverse=True)\n",
        "    if col_hits:\n",
        "        best_hits = col_hits[0][0]\n",
        "        best_col  = col_hits[0][1]\n",
        "        print(f\"[INFO] {csv_path.name} içinde '{best_col}' kolonu {best_hits} adet jpg ile örtüşüyor.\")\n",
        "\n",
        "        # Bu kolon üzerinden etiketle\n",
        "        if ycol is not None:\n",
        "            mapped_here = 0\n",
        "            for _, r in dfc.iterrows():\n",
        "                base = Path(str(r.get(best_col))).name\n",
        "                if base in jpg_names:\n",
        "                    lb = normalize_label(r.get(ycol))\n",
        "                    if lb is None:\n",
        "                        continue\n",
        "                    # jpg tam yolunu bul (aynı ad birden fazla yerdeyse ilkini al)\n",
        "                    jp = next((p for p in jpgs if p.name == base), None)\n",
        "                    if jp is not None:\n",
        "                        pairs.append((jp, lb))\n",
        "                        mapped_here += 1\n",
        "            print(f\"[INFO] CSV eşleme (doğrudan jpg adı): {csv_path.name} -> {mapped_here}\")\n",
        "    else:\n",
        "        print(f\"[INFO] {csv_path.name} içinde doğrudan jpg adı bulunamadı.\")\n",
        "\n",
        "# 5) Eğer CSV’den hâlâ kimliklendiremediysek, dosya adı deseninden etiket çıkar\n",
        "if not pairs:\n",
        "    print(\"\\n[WARN] CSV'den doğrudan jpg adı bulunamadı/etiketlenemedi. Dosya adı desenine bakılıyor…\")\n",
        "    # Örn: '1-xxxx.jpg' ve '2-xxxx.jpg' → 1=benign, 2=malignant (veya tersi).\n",
        "    prefix_counts = Counter([p.name.split('-')[0] if '-' in p.name else '' for p in jpgs])\n",
        "    print(\"[INFO] Dosya adı prefix dağılımı:\", dict(prefix_counts))\n",
        "    if set(prefix_counts.keys()) <= {'1','2',''} and prefix_counts.get('1',0) > 0 and prefix_counts.get('2',0) > 0:\n",
        "        prefix_to_label = {'1':'benign', '2':'malignant'}   # gerekirse tersine çevir\n",
        "        pairs = []\n",
        "        for p in jpgs:\n",
        "            pref = p.name.split('-')[0] if '-' in p.name else ''\n",
        "            lb = prefix_to_label.get(pref)\n",
        "            if lb is not None:\n",
        "                pairs.append((p, lb))\n",
        "        print(f\"[INFO] Dosya adı deseniyle etiketlenen örnek: {len(pairs)}\")\n",
        "    else:\n",
        "        raise RuntimeError(\"Ne CSV’de .jpg adı, ne de öngörülebilir dosya adı deseni bulundu. Eşleme yapılamadı.\")\n",
        "\n",
        "# 6) DataFrame ve split\n",
        "# aynı path tekrar ederse ilkini tut\n",
        "uniq = {}\n",
        "for p, lb in pairs:\n",
        "    uniq[str(p)] = lb\n",
        "rows = [(Path(k), v) for k,v in uniq.items()]\n",
        "\n",
        "df = pd.DataFrame(rows, columns=['path','label'])\n",
        "df['label_id'] = (df['label']=='malignant').astype(np.float32)\n",
        "df = df.drop_duplicates(subset=['path']).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n[OK] Etiket dağılımı:\")\n",
        "print(df['label'].value_counts(dropna=False))\n",
        "print(\"Toplam örnek:\", len(df))\n",
        "\n",
        "def guess_group(p):\n",
        "    p = Path(p)\n",
        "    parts = p.parts\n",
        "    return '/'.join(parts[-3:-1]) if len(parts) >= 3 else str(p.parent)\n",
        "\n",
        "df['group'] = df['path'].apply(guess_group)\n",
        "df = df.sample(frac=1.0, random_state=123).reset_index(drop=True)\n",
        "\n",
        "try:\n",
        "    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    idx_tr, idx_va = next(sgkf.split(df, y=df['label_id'], groups=df['group']))\n",
        "    df_train, df_val = df.iloc[idx_tr].reset_index(drop=True), df.iloc[idx_va].reset_index(drop=True)\n",
        "except Exception as e:\n",
        "    print(\"[WARN] SGKF olmadı, stratified split:\", e)\n",
        "    df_train, df_val = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label_id'])\n",
        "    df_train = df_train.reset_index(drop=True)\n",
        "    df_val   = df_val.reset_index(drop=True)\n",
        "\n",
        "print(f\"[OK] Split → Train: {len(df_train)}  Val: {len(df_val)}\")\n",
        "# =================== 5. KISIM SONU ===================\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0FbmTKWQeI_",
        "outputId": "e7039f1f-e752-4ccc-b401-d95e5125c715"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] JPG sayısı: 10237\n",
            "[INFO] Örnek JPG'ler: ['1-263.jpg', '2-241.jpg', '1-126.jpg', '1-231.jpg', '1-111.jpg', '1-031.jpg', '2-011.jpg', '1-108.jpg', '1-031.jpg', '1-075.jpg']\n",
            "[INFO] Kullanılacak CSV'ler: ['mass_case_description_test_set.csv', 'dicom_info.csv', 'mass_case_description_train_set.csv', 'calc_case_description_train_set.csv', 'calc_case_description_test_set.csv', 'meta.csv']\n",
            "[INFO] mass_case_description_test_set.csv içinde doğrudan jpg adı bulunamadı.\n",
            "[INFO] dicom_info.csv içinde 'image_path' kolonu 10237 adet jpg ile örtüşüyor.\n",
            "[INFO] mass_case_description_train_set.csv içinde doğrudan jpg adı bulunamadı.\n",
            "[INFO] calc_case_description_train_set.csv içinde doğrudan jpg adı bulunamadı.\n",
            "[INFO] calc_case_description_test_set.csv içinde doğrudan jpg adı bulunamadı.\n",
            "[INFO] meta.csv içinde doğrudan jpg adı bulunamadı.\n",
            "\n",
            "[WARN] CSV'den doğrudan jpg adı bulunamadı/etiketlenemedi. Dosya adı desenine bakılıyor…\n",
            "[INFO] Dosya adı prefix dağılımı: {'1': 6774, '2': 3463}\n",
            "[INFO] Dosya adı deseniyle etiketlenen örnek: 10237\n",
            "\n",
            "[OK] Etiket dağılımı:\n",
            "label\n",
            "benign       6774\n",
            "malignant    3463\n",
            "Name: count, dtype: int64\n",
            "Toplam örnek: 10237\n",
            "[OK] Split → Train: 8193  Val: 2044\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# ==== 6) DATASET & TFMS ==\n",
        "# (Senin istediğin gibi AYNI blok)\n",
        "# =========================\n",
        "IMG_SIZE = 512\n",
        "train_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, antialias=True),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.RandomHorizontalFlip(p=0.5),\n",
        "    T.RandomRotation(degrees=10),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "val_tfms = T.Compose([\n",
        "    T.Resize(IMG_SIZE, antialias=True),\n",
        "    T.CenterCrop(IMG_SIZE),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "])\n",
        "\n",
        "class MammoDataset(Dataset):\n",
        "    def __init__(self, frame: pd.DataFrame, tfms):\n",
        "        self.frame = frame.reset_index(drop=True)\n",
        "        self.tfms = tfms\n",
        "    def __len__(self): return len(self.frame)\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.frame.iloc[idx]\n",
        "        img = Image.open(row['path']).convert('RGB')  # gri de olsa 3 kanala çevir\n",
        "        x = self.tfms(img)\n",
        "        y = torch.tensor([row['label_id']], dtype=torch.float32)\n",
        "        return x, y\n",
        "\n",
        "BATCH_SIZE = 16\n",
        "NUM_WORKERS = 2\n",
        "train_ds = MammoDataset(df_train, train_tfms)\n",
        "val_ds   = MammoDataset(df_val,   val_tfms)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=NUM_WORKERS, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "u42qIeT0Qg-h"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device:\", DEVICE)\n",
        "# ---- 7) Model, Loss, Optimizer, Scheduler ----\n",
        "MODEL_NAME = 'efficientnet_v2_s'\n",
        "weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
        "model = efficientnet_v2_s(weights=weights)\n",
        "in_feats = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(in_feats, 1)  # binary logit\n",
        "model.to(DEVICE)\n",
        "\n",
        "pos_frac = max(1e-6, float(df_train['label_id'].mean()))\n",
        "neg_frac = 1.0 - pos_frac\n",
        "pos_weight = torch.tensor([neg_frac / pos_frac], device=DEVICE, dtype=torch.float32)\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "\n",
        "LR = 3e-4\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE=='cuda'))\n",
        "\n",
        "BEST_PATH = str(OUTPUT_DIR / 'best_cbis_ddsm.pt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itEwstw6Qg30",
        "outputId": "8a66822a-1dd3-4c27-e395-83d9cc4209aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1940992020.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE=='cuda'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 8) Eğitim (AMP + early stopping + CSV log) ----\n",
        "EPOCHS = 12\n",
        "EARLY_STOP_PATIENCE = 4\n",
        "best_auc = -1.0\n",
        "epochs_no_improve = 0\n",
        "history = []\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for imgs, ys in train_loader:\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        ys   = ys.to(DEVICE, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, ys)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer); scaler.update()\n",
        "        train_loss += loss.item() * imgs.size(0)\n",
        "    scheduler.step()\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "\n",
        "    # validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    y_true, y_prob = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, ys in val_loader:\n",
        "            imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "            ys   = ys.to(DEVICE, non_blocking=True)\n",
        "            with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "                logits = model(imgs)\n",
        "                loss = criterion(logits, ys)\n",
        "            val_loss += loss.item() * imgs.size(0)\n",
        "            y_true.extend(ys.detach().cpu().numpy().ravel().tolist())\n",
        "            y_prob.extend(torch.sigmoid(logits).detach().cpu().numpy().ravel().tolist())\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    try:\n",
        "        val_auc = roc_auc_score(y_true, y_prob)\n",
        "    except:\n",
        "        val_auc = float('nan')\n",
        "    y_pred = (np.array(y_prob) >= 0.5).astype(int)\n",
        "    val_acc = accuracy_score(y_true, y_pred)\n",
        "    val_f1  = f1_score(y_true, y_pred)\n",
        "\n",
        "    print(f\"[Epoch {epoch:02d}] train_loss={train_loss:.4f}  val_loss={val_loss:.4f}  AUC={val_auc:.4f}  ACC={val_acc:.4f}  F1={val_f1:.4f}\")\n",
        "\n",
        "    history.append({\"epoch\": epoch, \"train_loss\": float(train_loss), \"val_loss\": float(val_loss),\n",
        "                    \"val_auc\": float(val_auc) if not np.isnan(val_auc) else None,\n",
        "                    \"val_acc\": float(val_acc), \"val_f1\": float(val_f1),\n",
        "                    \"lr\": float(scheduler.get_last_lr()[0])})\n",
        "\n",
        "    if val_auc > best_auc:\n",
        "        best_auc = val_auc; epochs_no_improve = 0\n",
        "        torch.save({'model': model.state_dict(),\n",
        "                    'model_name': MODEL_NAME,\n",
        "                    'img_size': IMG_SIZE}, BEST_PATH)\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= EARLY_STOP_PATIENCE:\n",
        "            print(\"Early stopping tetiklendi.\"); break\n",
        "\n",
        "pd.DataFrame(history).to_csv(OUTPUT_DIR / 'train_log.csv', index=False)\n",
        "print(\"En iyi AUC:\", best_auc)\n",
        "print(\"Model kaydedildi:\", BEST_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AC8IrZ7QlWx",
        "outputId": "8b43d7d6-4e63-40bd-9738-51077827235a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 01] train_loss=0.4508  val_loss=0.4365  AUC=0.9445  ACC=0.8659  F1=0.8092\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 02] train_loss=0.3984  val_loss=0.3729  AUC=0.9451  ACC=0.8659  F1=0.8068\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 03] train_loss=0.4027  val_loss=0.3645  AUC=0.9504  ACC=0.8757  F1=0.8178\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 04] train_loss=0.3710  val_loss=0.3637  AUC=0.9504  ACC=0.8699  F1=0.8127\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 05] train_loss=0.3704  val_loss=0.3583  AUC=0.9512  ACC=0.8278  F1=0.7864\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 06] train_loss=0.3502  val_loss=0.3804  AUC=0.9501  ACC=0.8405  F1=0.7908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 07] train_loss=0.3416  val_loss=0.3491  AUC=0.9523  ACC=0.8439  F1=0.7972\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 08] train_loss=0.3325  val_loss=0.3760  AUC=0.9536  ACC=0.8581  F1=0.8079\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 09] train_loss=0.3236  val_loss=0.3510  AUC=0.9538  ACC=0.8415  F1=0.7944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 10] train_loss=0.3166  val_loss=0.3543  AUC=0.9539  ACC=0.8469  F1=0.7995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 11] train_loss=0.3110  val_loss=0.3496  AUC=0.9540  ACC=0.8439  F1=0.7954\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2539991457.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
            "/tmp/ipython-input-2539991457.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 12] train_loss=0.3121  val_loss=0.3532  AUC=0.9541  ACC=0.8420  F1=0.7947\n",
            "En iyi AUC: 0.9540882288358443\n",
            "Model kaydedildi: /content/drive/MyDrive/breast_cancer/best_cbis_ddsm.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 9) En iyi modeli yükle & değerlendir ----\n",
        "ckpt = torch.load(BEST_PATH, map_location=DEVICE)\n",
        "model = efficientnet_v2_s(weights=None)\n",
        "in_feats = model.classifier[1].in_features\n",
        "model.classifier[1] = nn.Linear(in_feats, 1)\n",
        "model.load_state_dict(ckpt['model']); model.to(DEVICE); model.eval()\n",
        "\n",
        "y_true, y_prob = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, ys in val_loader:\n",
        "        imgs = imgs.to(DEVICE, non_blocking=True)\n",
        "        ys   = ys.to(DEVICE, non_blocking=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "            logits = model(imgs)\n",
        "        y_true.extend(ys.detach().cpu().numpy().ravel().tolist())\n",
        "        y_prob.extend(torch.sigmoid(logits).detach().cpu().numpy().ravel().tolist())\n",
        "y_pred = (np.array(y_prob) >= 0.5).astype(int)\n",
        "\n",
        "val_auc = float(roc_auc_score(y_true, y_prob))\n",
        "val_acc = float(accuracy_score(y_true, y_pred))\n",
        "val_f1  = float(f1_score(y_true, y_pred))\n",
        "print(\"\\nValidation AUC:\", val_auc, \"ACC:\", val_acc, \"F1:\", val_f1)\n",
        "\n",
        "# CM görseli ve rapor\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred), display_labels=['benign','malignant'])\n",
        "disp.plot(ax=ax, values_format='d', colorbar=False)\n",
        "plt.title('Validation Confusion Matrix'); plt.tight_layout()\n",
        "cm_path = OUTPUT_DIR / 'confusion_matrix.png'\n",
        "plt.savefig(cm_path, dpi=150); plt.close(fig)\n",
        "\n",
        "report_txt = classification_report(y_true, y_pred, target_names=['benign','malignant'])\n",
        "with open(OUTPUT_DIR / 'classification_report.txt', 'w') as f: f.write(report_txt)\n",
        "\n",
        "val_pred_df = pd.DataFrame({\n",
        "    \"path\": [str(p) for p in df_val['path'].tolist()],\n",
        "    \"label\": df_val['label'].tolist(),\n",
        "    \"prob_malignant\": list(np.array(y_prob)),\n",
        "    \"pred_label\": ['malignant' if i==1 else 'benign' for i in y_pred]\n",
        "})\n",
        "val_pred_df.to_csv(OUTPUT_DIR / 'val_predictions.csv', index=False)\n",
        "\n",
        "metrics = {\"val_auc\": val_auc, \"val_accuracy\": val_acc, \"val_f1\": val_f1}\n",
        "with open(OUTPUT_DIR / 'metrics.json', 'w') as f: json.dump(metrics, f, indent=2)\n",
        "\n",
        "print(\"\\nKaydedildi:\")\n",
        "for p in [\"train_log.csv\",\"confusion_matrix.png\",\"classification_report.txt\",\"val_predictions.csv\",\"metrics.json\",\"best_cbis_ddsm.pt\"]:\n",
        "    print(\" -\", OUTPUT_DIR / p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxBbpYStQrCB",
        "outputId": "be2f5dbc-dfce-4482-82b4-0a88308ca3aa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1754347368.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation AUC: 0.9540882288358443 ACC: 0.8419765166340509 F1: 0.7946598855689765\n",
            "\n",
            "Kaydedildi:\n",
            " - /content/drive/MyDrive/breast_cancer/train_log.csv\n",
            " - /content/drive/MyDrive/breast_cancer/confusion_matrix.png\n",
            " - /content/drive/MyDrive/breast_cancer/classification_report.txt\n",
            " - /content/drive/MyDrive/breast_cancer/val_predictions.csv\n",
            " - /content/drive/MyDrive/breast_cancer/metrics.json\n",
            " - /content/drive/MyDrive/breast_cancer/best_cbis_ddsm.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 10) Basit TTA (flip) ----\n",
        "def predict_with_tta(model, loader):\n",
        "    probs = []\n",
        "    with torch.no_grad():\n",
        "        for imgs, _ in loader:\n",
        "            imgs = imgs.to(DEVICE)\n",
        "            with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n",
        "                p1 = torch.sigmoid(model(imgs)).detach().cpu().numpy().ravel()\n",
        "                p2 = torch.sigmoid(model(torch.flip(imgs, dims=[3]))).detach().cpu().numpy().ravel()\n",
        "            probs.extend(((p1 + p2) / 2.0).tolist())\n",
        "    return np.array(probs)\n",
        "\n",
        "tta_prob = predict_with_tta(model, val_loader)\n",
        "tta_auc = float(roc_auc_score(y_true, tta_prob))\n",
        "with open(OUTPUT_DIR / 'metrics.json', 'r') as f: m = json.load(f)\n",
        "m['tta_auc'] = tta_auc\n",
        "with open(OUTPUT_DIR / 'metrics.json', 'w') as f: json.dump(m, f, indent=2)\n",
        "print(\"TTA AUC:\", tta_auc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppnKMAAkQw5y",
        "outputId": "99d60963-7d96-485f-f099-be4eeefc4693"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3963247420.py:7: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda')):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TTA AUC: 0.9547951734960021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- 11) Görsel özetler (metrik bar, ROC, PR, pie) ----\n",
        "# 1) Metrik bar grafiği\n",
        "metrics_plot = {\"Accuracy\": val_acc, \"F1\": val_f1, \"AUC\": val_auc}\n",
        "if 'tta_auc' in m: metrics_plot['TTA AUC'] = float(m['tta_auc'])\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(list(metrics_plot.keys()), list(metrics_plot.values()))\n",
        "plt.ylim(0, 1.0); plt.ylabel(\"Score\"); plt.title(\"Validation Metrics\")\n",
        "for i,(k,v) in enumerate(metrics_plot.items()):\n",
        "    plt.text(i, min(0.98, v)+0.02, f\"{v:.3f}\", ha='center', va='bottom', fontsize=9)\n",
        "plt.tight_layout(); plt.savefig(OUTPUT_DIR / 'metrics_bar.png', dpi=150); plt.close()\n",
        "\n",
        "# 2) ROC\n",
        "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
        "auc_val = roc_auc_score(y_true, y_prob)\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(fpr, tpr, label=f\"AUC = {auc_val:.3f}\")\n",
        "plt.plot([0,1], [0,1], linestyle='--')\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve (Validation)\"); plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout(); plt.savefig(OUTPUT_DIR / 'roc_curve.png', dpi=150); plt.close()\n",
        "\n",
        "# 3) Precision-Recall\n",
        "prec, rec, _ = precision_recall_curve(y_true, y_prob)\n",
        "ap = average_precision_score(y_true, y_prob)\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(rec, prec, label=f\"AP = {ap:.3f}\")\n",
        "plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve (Validation)\"); plt.legend(loc=\"lower left\")\n",
        "plt.tight_layout(); plt.savefig(OUTPUT_DIR / 'pr_curve.png', dpi=150); plt.close()\n",
        "\n",
        "# 4) Tahmin edilen sınıf oranları\n",
        "pred_counts = pd.Series(y_pred).value_counts()\n",
        "benign_cnt = int(pred_counts.get(0, 0))\n",
        "malig_cnt  = int(pred_counts.get(1, 0))\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.pie([benign_cnt, malig_cnt], labels=[\"benign\", \"malignant\"], autopct=\"%1.1f%%\", startangle=90)\n",
        "plt.title(\"Predicted Class Ratios (Validation)\")\n",
        "plt.tight_layout(); plt.savefig(OUTPUT_DIR / 'predicted_ratios_pie.png', dpi=150); plt.close()\n",
        "\n",
        "# (Opsiyonel) Ground Truth oranları\n",
        "gt_counts = pd.Series(np.array(y_true).astype(int)).value_counts()\n",
        "benign_gt = int(gt_counts.get(0, 0))\n",
        "malig_gt  = int(gt_counts.get(1, 0))\n",
        "plt.figure(figsize=(5,5))\n",
        "plt.pie([benign_gt, malig_gt], labels=[\"benign\",\"malignant\"], autopct=\"%1.1f%%\", startangle=90)\n",
        "plt.title(\"Ground Truth Class Ratios (Validation)\")\n",
        "plt.tight_layout(); plt.savefig(OUTPUT_DIR / 'ground_truth_ratios_pie.png', dpi=150); plt.close()\n",
        "\n",
        "print(\"\\nGörseller kaydedildi:\")\n",
        "for f in [\"metrics_bar.png\",\"roc_curve.png\",\"pr_curve.png\",\"predicted_ratios_pie.png\",\"ground_truth_ratios_pie.png\"]:\n",
        "    print(\" -\", OUTPUT_DIR / f)\n",
        "\n",
        "print(\"\\nTamamlandı →\", OUTPUT_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZBH4RoFQ17r",
        "outputId": "abf6f9ff-4bbc-4bf6-ae47-df05d6f3433e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Görseller kaydedildi:\n",
            " - /content/drive/MyDrive/breast_cancer/metrics_bar.png\n",
            " - /content/drive/MyDrive/breast_cancer/roc_curve.png\n",
            " - /content/drive/MyDrive/breast_cancer/pr_curve.png\n",
            " - /content/drive/MyDrive/breast_cancer/predicted_ratios_pie.png\n",
            " - /content/drive/MyDrive/breast_cancer/ground_truth_ratios_pie.png\n",
            "\n",
            "Tamamlandı → /content/drive/MyDrive/breast_cancer\n"
          ]
        }
      ]
    }
  ]
}